#! /usr/bin/env node

require('dotenv').config({path: `${__dirname}/.env`});
const yargs = require('yargs/yargs');
const {hideBin} = require('yargs/helpers')
const argv = yargs(hideBin(process.argv))
    .default({size: '1024x768'})
    .demandOption(['room'])
    .describe('size', 'The size of recorded video(s)')
    .describe('room', 'The ID of the room to record')
    .describe('audioOnly', 'Pass this option if you\'d like to only record the audio of the given room').argv;

const ffmpeg = require("fluent-ffmpeg");
const rmdir = require("rimraf");
const glob = require('glob');
const {filter: _filter, find: _find} = require('lodash');

const VIDEO_OUTPUT_SIZE = argv.size;
const VIDEO_INPUT_DIR = `./storage/app/${argv.room}`;
const VIDEO_OUTPUT_FILE = `./storage/app/public/recordings/${argv.room}`;
let root;       // Number of video cells in one dimension of the grid.
let firstPeerTime = Math.floor(Date.now());

/**
 * Gets xstack compatible width or height coordinate e.g. 0, w0 or, h0+h0.
 * The first cell's w and / or h is used as all cells are of the same size in this application.
 *
 * @param axis 'w' for width or 'h' for height.
 * @param value number of the w or h cell starts from zero.
 * @returns string
 */
function coordinate(axis, value){
    if(value == 0)
        return 0;
    let coordinate = [];
    for(let i = 0; i < value; i++)
        coordinate.push(axis + '0');
    return coordinate.join('+');
}

/**
 * Gets xstack compatible layout string e.g. 0_0|w0_0 for the given cells as square grid.
 *
 * @param cells How many cells in the layout.
 * @returns string
 */
function layout(cells){
    root = Math.sqrt(cells), layout = [];
    while(root - Math.floor(root) != 0){
        cells++;
        root = Math.sqrt(cells);
    }
    for(var h = 0; h < root; h++)
        for(var w = 0; w < root; w++)
            layout.push(coordinate('w', w) + '_' + coordinate('h', h));
    return layout.join('|');
}

let files = [];
glob.sync(`${VIDEO_INPUT_DIR}/*.mp*`).forEach((file) => {
    let timestamp = parseInt(file.split('-')[1].match(/[0-9]+/));
    files.push({
        filename: file,
        timestamp,
        delay: 0,
        audioOnly: /\.mp3$/.test(file)
    });
    if(timestamp < firstPeerTime)
        firstPeerTime = timestamp;
});
let proc = ffmpeg().on('start', () => {
    console.log('Start merging into ' + VIDEO_OUTPUT_FILE);
}).on('end', () => {
    rmdir.sync(VIDEO_INPUT_DIR);
    console.log('Finished merging ' + VIDEO_OUTPUT_FILE);
    process.exit();
}), audioOnly = argv.audioOnly || (_find(files, {audioOnly: false}) === undefined), filters = [], i = 0,
    videosCount = _filter(files, {audioOnly: false}).length;
let videoStack = '', audioStack = '', grid = layout(videosCount);
files.forEach((file) => {
    proc.addInput(file.filename);
    file.delay = file.timestamp - firstPeerTime;

    if(file.delay == 0){
        audioStack += `[${i}:a]`;
        if(!audioOnly && !file.audioOnly)
            videoStack += `[${i}:v]`;
    } else{
        filters.push(`[${i}:a]adelay=delays=${file.delay}s:all=1[audio${i}]`);
        audioStack += `[audio${i}]`;
        if(!audioOnly && !file.audioOnly){
            filters.push(`[${i}:v]tpad=start_duration=${file.delay}s[video${i}]`);
            videoStack += `[video${i}]`;
        }
    }
    i++;
});
let outputOptions = ['-map [aout]'];
if(!audioOnly){
    outputOptions.push('-map [v]');
    if(root * root > videosCount && videosCount % root == 0){
        proc.addInput(`${__dirname}/black.mp4`);
        videoStack += `[${videosCount}]`;
        videosCount++;
    }
    videoStack += `xstack=inputs=${videosCount}:layout=${grid}:fill=black[m]`;
    filters.push(videoStack, `[m]scale=${VIDEO_OUTPUT_SIZE}[v]`);
}
filters.push(`${audioStack}amix=inputs=${files.length}:normalize=0[aout]`);
if(filters.length)
    proc.complexFilter(filters);
proc.outputOptions(outputOptions);
proc.output(VIDEO_OUTPUT_FILE + (audioOnly? '.mp3' : '.mp4')).run();
